# ============================================================================
# Docker Compose Configuration
# Project: Local AI Platform (OpenWebUI, Searxng, LiteLLM, Postgres, n8n, Ollama, etc.)
# Author: Erik van Busschbach
# Last updated: 2025-08-11
# Version: 250811v7-DRY
# Description:
#   - Defines Docker services for the Local AI platform.
#   - Uses DRY principles for environment variable management.
#   - Secure DB initialization and environment variable passing.
#   - Modular and easy to extend with clean logs and health checks.
# ============================================================================

volumes:
  open_webui_:
  searxng_:
  litellm_:
  postgres_:
# redis_:   # Uncomment if Redis enabled

networks:
  ai_network:

x-service-defaults: &defaults
  restart: unless-stopped
  networks:
    - ai_network

services:

  # --- OpenWebUI frontend ---
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    environment:
      - ENABLE_RAG_WEB_SEARCH=true
      - RAG_WEB_SEARCH_ENGINE=searxng
      - RAG_WEB_SEARCH_RESULT_COUNT=3
      - SEARXNG_QUERY_URL=http://searxng:8080/search
    ports:
      - "${OPENWEBUI_PORT}:8080"
    volumes:
      - open_webui_:/app/backend/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - searxng
    <<: *defaults

  # --- SearxNG meta search engine ---
  searxng:
    image: searxng/searxng:latest
    ports:
      - "${SEARXNG_PORT}:8080"
    volumes:
      - searxng_:/etc/searxng
    environment:
      - SEARXNG_BIND_ADDRESS=0.0.0.0:8080
      - SEARXNG_BASE_URL=http://localhost:${SEARXNG_PORT}/
      - SEARXNG_LIMITER=false
    <<: *defaults

  # --- PostgreSQL database ---
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=${POSTGRES_SUPERUSER}        # Required by postgres image
      - POSTGRES_SUPERUSER=${POSTGRES_SUPERUSER}  # Explicit for init scripts & scripts
      - POSTGRES_PASSWORD=${POSTGRES_SUPERPASS}
      - POSTGRES_DB=${POSTGRES_DB}
      - APP_DATABASES=${APP_DATABASES}             # Used by init-multiple-dbs.sh to create all needed DBs and users dynamically
    volumes:
      - postgres_:/var/lib/postgresql/data
      - ./init-multiple-dbs.sh:/docker-entrypoint-initdb.d/init-multiple-dbs.sh:ro
    ports:
      - "${POSTGRES_PORT}:5432"
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_SUPERUSER} -d ${POSTGRES_DB}']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    <<: *defaults

  # --- LiteLLM API proxy ---
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "${LITELLM_PORT}:4000"
    env_file: .env        # Load the entire environment from .env as source of truth
    environment:
      # Explicit mapping to guarantee these critical vars get passed in
      DATABASE_URL: ${DATABASE_URL}
      LITELLM_DATABASE_URL: ${LITELLM_DATABASE_URL}
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      LITELLM_SALT_KEY: ${LITELLM_SALT_KEY}
      STORE_MODEL_IN_DB: ${STORE_MODEL_IN_DB}
      LITELLM_LOG: ${LITELLM_LOG}
      APP_DATABASES: ${APP_DATABASES}              # Optional: pass to litellm if used internally
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_SUPERUSER: ${POSTGRES_SUPERUSER}
    volumes:
      - ./litellm_config:/app/config                # Your LiteLLM config.yaml here, must be mounted
      - litellm_:/app/data                         # Persistent data volume for LiteLLM
    depends_on:
      postgres:
        condition: service_healthy
    <<: *defaults

#  # --- Redis cache (optional) ---
#  redis:
#    image: redis:7-alpine
#    ports:
#      - "${REDIS_PORT}:6379"
#    command: redis-server --appendonly yes
#    volumes:
#      - ./redis:/data
#    <<: *defaults